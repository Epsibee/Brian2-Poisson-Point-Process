{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324ea187-1cee-4d5a-bbd3-b1f58505a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # used for array operations\n",
    "import brian2 as b2 # used for neural simulation\n",
    "from scipy.stats import poisson, binom # used for stats (mean, s.d.)\n",
    "import matplotlib.pyplot as plt # used for plotting\n",
    "import pickle # used for saving data\n",
    "b2.prefs.codegen.target = \"numpy\" # set Brian2 to use numpy backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "258fe9f4-8f29-48b3-a26d-0d07a3ad7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulates multiple independent Poisson processes for a group of neurons\n",
    "def independent_poisson_processes(num_neurons, rate, time, num_samples): \n",
    "    # Convert time to seconds to Brian2 units\n",
    "    simulation_time = time * b2.second\n",
    "    # Number of time bins (in milisecs) used to discretize\n",
    "    n_bins = int(time)\n",
    "    \n",
    "    #3D array to store spike trains of parameters\n",
    "    processes = np.zeros((num_samples, num_neurons, n_bins))\n",
    "\n",
    "    # tried to vectorize and use for-loops as least as possible, some remain\n",
    "    for sample in range(num_samples):\n",
    "\n",
    "        # Create Poisson neurons and monitor their spikes\n",
    "        poisson_group = b2.PoissonGroup(num_neurons, rate * b2.Hz) # represents the neurons created, firing at the specified rate with int and rate\n",
    "        spike_monitor = b2.SpikeMonitor(poisson_group) # records the spikes genreated by the poissongroup with source\n",
    "\n",
    "        # create a network\n",
    "        net = b2.Network(poisson_group, spike_monitor)\n",
    "        # run the network\n",
    "        net.run(simulation_time)\n",
    "        \n",
    "        # obtaining spike times for each neuron\n",
    "        spike_trains = spike_monitor.spike_trains() \n",
    "\n",
    "        # Convert continuous spike times to discrete time bins\n",
    "        spike_indices = np.array([np.floor(t / b2.ms) for t in spike_trains[0] if t < simulation_time])\n",
    "        \n",
    "        # Mark spike occurrences in the processes array\n",
    "        processes[sample, 0, spike_indices.astype(int)] = 1\n",
    "    \n",
    "    return processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2cc2880-df77-42f9-9364-acb1cd081b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd72c1f6-60fe-48c2-bf4e-ac3e87bfdf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce48591-e700-4638-86b9-fd814003564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sums across neurons to get population activity\n",
    "def calculate_population_activity(processes):\n",
    "    return np.sum(processes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f27113-56b2-410d-879d-6bac10581a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total spikes for each neuron in each sample\n",
    "def calculate_spike_counts(processes):\n",
    "    return np.sum(processes, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d66e10a7-8385-441f-8149-c7fa9f977ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum spike counts across neurons for each sample\n",
    "def calculate_total_spike_counts(spike_counts):\n",
    "    return np.sum(spike_counts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f75d1af1-0b44-4c1e-a787-1aa43359fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average spike count across all samples\n",
    "def calculate_average_spike_count(total_spike_counts):\n",
    "    return np.mean(total_spike_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27f023a-e48e-4896-b725-3254e6a9e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neurons with minimum spike count\n",
    "def find_minimum_spike_count(spike_counts):\n",
    "    minimum_spike_count = np.min(spike_counts)\n",
    "    minimum_spike_count_indices = np.where(spike_counts == minimum_spike_count)\n",
    "    minimum_spike_count_integers = np.arange(1, minimum_spike_count + 1)\n",
    "    return minimum_spike_count, minimum_spike_count_indices, minimum_spike_count_integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e65915-3b63-447d-af20-b69f3d9a6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlated_poisson_processes(num_neurons, rate, time, num_common, num_samples):\n",
    "    # Create a network with independent Poisson neurons\n",
    "    # Each neuron is reprsented by a seperate PoissonGroup with rate\n",
    "    net = b2.Network()\n",
    "    poisson_groups = [b2.PoissonGroup(1, rate*b2.Hz) for _ in range((num_neurons + num_common) * num_samples)]\n",
    "    net.add(poisson_groups)\n",
    "    \n",
    "    # Setting up spike monitors to record the activity of each neuron with a simulation run\n",
    "    spike_monitors = [b2.SpikeMonitor(group) for group in poisson_groups]\n",
    "    net.add(spike_monitors)\n",
    "    net.run(time * b2.ms) # should all of the b2.ms be (t/b2.ms)*10) ????\n",
    "\n",
    "    # Convert spike trains for Brian2 format to numpy arrays, intialize storing process, convert spike times to discrete time indicies\n",
    "    spike_trains = [monitor.spike_trains()[0] for monitor in spike_monitors]\n",
    "    independent_procs = np.zeros((num_samples, num_neurons + num_common, int(time)), dtype=bool)\n",
    "    spike_indices_list = [[int(t / b2.ms) for t in spike_train if t < time * b2.ms] for spike_train in spike_trains]\n",
    "\n",
    "    # Ensuring all spike trains have the same length by padding with zeros\n",
    "    max_length = max(len(indices) for indices in spike_indices_list)\n",
    "    padded_spike_indices_list = [indices + [0] * (max_length - len(indices)) for indices in spike_indices_list]\n",
    "\n",
    "    # Convert padded lists to numpy array for efficient processing\n",
    "    spike_indices = np.array(padded_spike_indices_list)\n",
    "\n",
    "    # Calculate sample and neuron idicies for efficient array indexing\n",
    "    sample_indices, neuron_indices = np.divmod(np.arange((num_neurons + num_common) * num_samples), num_neurons + num_common)\n",
    "    for i, indices in enumerate(spike_indices):\n",
    "        for index in indices:\n",
    "            if index < int(time):\n",
    "                independent_procs[sample_indices[i], neuron_indices[i], index] = True\n",
    "\n",
    "    # Generate correlated processes:\n",
    "    correlated_procs = np.zeros((num_samples, num_neurons, int(time)), dtype=bool) #  by combining independent processes\n",
    "    correlated_procs[:, :num_common, :] = np.cumsum(independent_procs[:, :num_common, :], axis=2) # num_common neurons are correlated through cumsum\n",
    "    correlated_procs[:, num_common:, :] = independent_procs[:, num_common:num_neurons, :] # remaining neurons maintain their independent firing patterns\n",
    "\n",
    "    return correlated_procs # should this return more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf814e56-1904-481e-87e6-ff2ae4b8184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_network(num_neurons, rate, time):\n",
    "    neurons = b2.NeuronGroup(num_neurons, 'dv/dt = -v/(10*ms) : 1', threshold='v>1', reset='v=0')\n",
    "    inputs = b2.PoissonInput(target=neurons, target_var='v', N=num_neurons, rate=rate*b2.Hz, weight=1)\n",
    "    spike_monitor = b2.SpikeMonitor(neurons)\n",
    "    net = b2.Network(neurons, inputs, spike_monitor)\n",
    "    net.run(time * b2.ms)  # Run the network instead of b2.run\n",
    "    return spike_monitor.spike_trains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417d20bd-62b7-44f7-88a4-452b22254f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start - counting functions\n",
    "\n",
    "# The counting functions are designed to calculate the number of spikes in a neuron or a group of neurons over time.\n",
    "# These functions take in an array of spike counts and return the cumulative sum of the spike counts up to a specified time.\n",
    "# The count_at_time function calculates the cumulative sum of the spike counts up to a specified time t,\n",
    "# while the count1 function calculates the cumulative sum of the spike counts for a single neuron over time.\n",
    "# The countall function calculates the cumulative sum of the spike counts for all neurons over time,\n",
    "# and the counting_process_nd function calculates the cumulative sum of the spike counts for multiple neurons over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a32ae1d-d8e2-4102-a5f9-4f64ce7b6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_at_time(counts, times, t):\n",
    "    return np.cumsum(counts[:np.sum(times < t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd1d3cd0-4f2a-400c-aa0b-d410d05309c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count1(process, time):\n",
    "    # **Changed to use np.cumsum** # this is discrete because we need continuous model\n",
    "    return np.cumsum(process)[:time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9830351-e9db-42d0-a2e9-f8efaebdfa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countall(processes, time):\n",
    "    counts = []\n",
    "    for process in processes:\n",
    "        count = count1(process, time)\n",
    "        counts.append(count)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ba5193a-b3af-4d68-a645-cddcadc450f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_process_nd(independent_processes, num_samples, time, num_neurons_to_plot):\n",
    "    counting_process_nd = [[[0 for _ in range(time)] for _ in range(num_neurons_to_plot)] for _ in range(num_samples)]\n",
    "    for i in range(num_samples):\n",
    "        counts = [0] * num_neurons_to_plot\n",
    "        for j in range(time):\n",
    "            for k in range(num_neurons_to_plot):\n",
    "                if independent_processes[i][k][j] == 1:\n",
    "                    counts[k] += 1\n",
    "            for k in range(num_neurons_to_plot):\n",
    "                counting_process_nd[i][k][j] = counts[k]\n",
    "    return counting_process_nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4c30b53-fba7-4fe6-903a-f67c9edc2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end - counting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67337293-1e54-4d71-86d1-dfb8ad092ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start - plot functions\n",
    "\n",
    "# The plotting functions are designed to visualize the spike counts and other data.\n",
    "# The plot_neurons_spiking function plots the spike counts for multiple neurons over time,\n",
    "# while the plot_neuron_spiking_standard_dev function plots the spike counts for a single neuron over time,\n",
    "# along with the mean and standard deviation of the spike counts.\n",
    "# The plot_two_neurons_against_time function plots the spike counts for two neurons over time,\n",
    "# along with the cumulative sum of the spike counts for a third neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5828d6ab-f4b1-4a4a-9a12-686d85e29bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neurons_spiking(processes, time): # showing some examples of neurons spiking\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    for i in range(len(processes[0])):\n",
    "        plt.plot(processes[0][i], label=f'Neuron {i}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Spike')\n",
    "    plt.title('Neurons Over Time')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "102ffc2f-abb0-4c59-b731-fd82ace4483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neuron_spiking_standard_dev(processes, time):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    plt.plot(processes[0][0], label='Neuron 1')\n",
    "    sd = np.std(processes[0][0])\n",
    "    mean = np.mean(processes[0][0])\n",
    "    print(f\"Mean: {mean:.2f}\")\n",
    "    print(f\"Standard Deviation: {sd:.2f}\")\n",
    "    plt.fill_between(range(time), processes[0][0] - sd, processes[0][0] + sd, alpha=0.2, label='Standard Deviation')\n",
    "    plt.axhline(y=mean, color='black', linestyle='--', label='Mean')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Spike')\n",
    "    plt.title('Neuron 1 Over Time with Standard Deviation')\n",
    "    plt.legend()\n",
    "    plt.text(0.5, 0.9, f\"Mean: {mean:.2f}, SD: {sd:.2f}\", transform=plt.gca().transAxes)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "429b829c-cce0-401f-8318-fa4e8a5c8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_neurons_against_time(processes, time):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot(processes[0][0], processes[0][1], np.cumsum(processes[0][2]))\n",
    "    ax.set_xlabel('Neuron 1')\n",
    "    ax.set_ylabel('Neuron 2')\n",
    "    ax.set_zlabel('Cumulative Sum of Neuron 3')\n",
    "    plt.title('Two Neurons Over Time with Cumulative Sum of Third Neuron')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "108b9b77-2ca8-4665-bab9-ae8b5bdd7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_count_neuron1_vs_time(counting_process_nd, num_samples):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for i in range(num_samples):\n",
    "        plt.plot(counting_process_nd[i][0], label=f'Sample {i}')\n",
    "    mean_neuron1 = np.mean([counting_process_nd[i][0] for i in range(num_samples)], axis=0)\n",
    "    plt.plot(mean_neuron1, label='Mean', color='black', linewidth=2)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Count of Neuron 1')\n",
    "    plt.title('Count of Neuron 1 Over Time')\n",
    "    plt.ylim(0, None)  # Set y-axis lower limit to 0\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33ee9a15-87da-44b2-b231-e89bf8d6d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_count_neuron1_vs_neuron2_vs_time(counting_process_nd, num_samples):\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for i in range(num_samples):\n",
    "        ax.plot(counting_process_nd[i][0], counting_process_nd[i][1], range(len(counting_process_nd[i][0])))\n",
    "    mean_neuron1 = np.mean([counting_process_nd[i][0] for i in range(num_samples)], axis=0)\n",
    "    mean_neuron2 = np.mean([counting_process_nd[i][1] for i in range(num_samples)], axis=0)\n",
    "    ax.plot(mean_neuron1, mean_neuron2, range(len(mean_neuron1)), color='black', linewidth=2)\n",
    "    ax.set_xlabel('Count of Neuron 1')\n",
    "    ax.set_ylabel('Count of Neuron 2')\n",
    "    ax.set_zlabel('Time', rotation=90)\n",
    "    ax.set_title('Count of Neuron 1 vs Count of Neuron 2 vs Time')\n",
    "    ax.set_xlim(0, max([max(counting_process_nd[i][0]) for i in range(num_samples)]))\n",
    "    ax.set_ylim(0, max([max(counting_process_nd[i][1]) for i in range(num_samples)]))\n",
    "    ax.set_zlim(0, max([len(counting_process_nd[i][0]) for i in range(num_samples)]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1c30e82-64f1-4992-8919-32990803c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_count1(count1_output, title='Count of Spikes Over Time (Single Neuron)'):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(count1_output)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    print(f\"Plot of {title} generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84bf90a5-6a6b-46bd-9193-ef72f7f1d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vectorized_count1(count1_vectorized_output, title='Count of Spikes Over Time (Single Neuron, Vectorized)'):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(count1_vectorized_output)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    print(f\"Plot of {title} generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "add11660-beb8-4185-bddd-020dd2e1fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts(counts_all, title='Count of Spikes Over Time'):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for i, count in enumerate(counts_all):\n",
    "        plt.plot(count, label=f'Neuron {i}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3da5b02-b9d3-4937-96fa-31c621c26403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts_vectorized(counts_all_vectorized, title='Count of Spikes Over Time (Vectorized)'):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for i, count in enumerate(counts_all_vectorized):\n",
    "        plt.plot(count, label=f'Neuron {i}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91cca672-4543-4305-bbc0-8f44af7a7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_covariance(covariance, time):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time, covariance)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Covariance')\n",
    "    plt.title('Covariance between Neuron Counts 1 and 2 over Time')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ccb5bb0-ad7b-4854-9ac3-507ca56ed882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end - plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b2393fe-215a-4028-a697-98a89f92a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start - stats functions\n",
    "\n",
    "# The statistical functions are designed to calculate statistical properties of the spike counts.\n",
    "# These functions take in an array of spike counts and return statistical properties such as the mean, covariance, and slope of the spike counts. \n",
    "# The calculate_mean_and_covariance function calculates the mean and covariance of the spike counts for multiple neurons\n",
    "# over time, while the get_slope function calculates the slope of the spike counts for multiple neurons over time.\n",
    "# The calculate_mean_with_std function calculates the mean and standard deviation of the spike counts for a single neuron over time,\n",
    "# and the calculate_covariance_matrix function calculates the covariance matrix of the spike counts for multiple neurons over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5eedc279-1fb5-44e8-b179-2b141c7aa73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_covariance(processes):\n",
    "    means = []\n",
    "    covariances = []\n",
    "    for i in range(len(processes[0])):\n",
    "        mean = np.mean([process[i] for process in processes])\n",
    "        covariance = np.cov([process[i] for process in processes], rowvar=False)\n",
    "        means.append(mean)\n",
    "        covariances.append(covariance)\n",
    "    return means, covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fea8de4-a7ea-497e-9019-d15141a9df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_covariance(processes):\n",
    "    num_samples, num_neurons, n_bins = processes.shape\n",
    "    covariance = np.zeros((n_bins,))\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        neuron1_counts = processes[:, 0, i]\n",
    "        neuron2_counts = processes[:, 1, i]\n",
    "        covariance[i] = np.cov(neuron1_counts, neuron2_counts)[0, 1]\n",
    "\n",
    "    return covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18f8bf20-db7f-4137-891a-14a7079058a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_covariance_over_neurons(covariance):\n",
    "    return np.mean(covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1a3ae92-7aaa-41e5-82e3-b52b296a78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_counts_in_time_windows(processes, time_windows):\n",
    "    num_samples, num_neurons, n_bins = processes.shape\n",
    "    mean_counts = []\n",
    "    covariance_counts = []\n",
    "\n",
    "    for start, end in time_windows:\n",
    "        start_idx = int(start * 1000)\n",
    "        end_idx = int(end * 1000)\n",
    "        window_processes = processes[:, :, start_idx:end_idx]\n",
    "\n",
    "        mean_count = np.mean(np.sum(window_processes, axis=2))\n",
    "        covariance_count = calculate_covariance(window_processes)\n",
    "\n",
    "        mean_counts.append(mean_count)\n",
    "        covariance_counts.append(covariance_count)\n",
    "\n",
    "    return mean_counts, covariance_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0556cf8-490b-42fc-b559-9c4ffbb69bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_homogenous_poisson_process(rate, simulation_time):\n",
    "    import numpy as np\n",
    "\n",
    "    # Generate Poisson process using numpy's random.poisson function\n",
    "    poisson_process = np.random.poisson(rate * simulation_time)\n",
    "\n",
    "    return poisson_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5c4fa81-6896-4cf2-a886-b0e0b6ce81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(processes):\n",
    "    slopes = []\n",
    "    for i in range(len(processes[0])):\n",
    "        slope = np.polyfit(range(len(processes[0][i])), processes[0][i], 1)[0]\n",
    "        slopes.append(slope)\n",
    "    return slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a3c1f17-17a5-49bf-86ab-4322a176b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_with_std(processes):\n",
    "    mean_with_std = np.mean(processes[0][0]) + np.std(processes[0][0])\n",
    "    return mean_with_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d5f2fff-f212-4e93-b7d3-eb41e5a1b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_covariance_matrix(processes):\n",
    "    cov_matrix = np.cov([processes[0][0], processes[0][1]])\n",
    "    return cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6b1990b-55b4-4ddd-9716-a9fd92a39d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end - stats functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faecba9d-fa69-48d4-b307-a428b3bbfc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start -  Discretize time and sampling functions\n",
    "\n",
    "# The discretization and sampling functions are designed to discretize the time values into bins of a specified size and sample\n",
    "# the spike counts at a specified resolution. The discretize_time function discretizes the time values into bins of a specified size,\n",
    "# while the sample_spikes function samples the spike counts at a specified resolution.\n",
    "# These functions are useful for analyzing the spike counts at different time scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3b9aad8-59e0-4363-b5fb-97fde47cbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_time(processes, time):\n",
    "    discretized_processes = []\n",
    "    for process in processes:\n",
    "        discretized_process = np.array([process[i] for i in range(0, len(process), time)])\n",
    "        discretized_processes.append(discretized_process)\n",
    "    return discretized_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "837fe1e1-1896-4f3c-a3e3-31a16627d9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_spikes(processes, resolution):\n",
    "    sampled_processes = []\n",
    "    for process in processes:\n",
    "        sampled_process = process[::resolution]\n",
    "        sampled_processes.append(sampled_process)\n",
    "    return sampled_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80706b5f-2abc-4aaa-b2fe-33588e6d5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end -  Discretize time and sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fb0db37-714e-4706-babc-38e4b6591867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start - tagging and branding functions\n",
    "\n",
    "# The tagging and branding functions are designed to tag each event in the spike counts with a Poisson process and simulate\n",
    "# a network of neurons. The tag_events_with_poisson function tags each event in the spike counts with a Poisson process,\n",
    "# while the brand_networks function simulates a network of neurons with a specified number of neurons, firing rate, and time,\n",
    "# and returns the spike trains of the neurons. These functions are useful for analyzing the behavior of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "570a92df-5e7a-46d3-a887-212b499ce898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_events_with_poisson(processes, rate):\n",
    "    if isinstance(processes, (np.float64, float, int)):\n",
    "        # If single value, return single Poisson sample\n",
    "        return np.random.poisson(rate)\n",
    "    else:\n",
    "        # If array, process as before\n",
    "        tagged_processes = []\n",
    "        for process in processes:\n",
    "            tagged_process = np.random.poisson(rate, size=len(process))\n",
    "            tagged_processes.append(tagged_process)\n",
    "        return tagged_processes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "061873aa-ea6e-417b-8551-90d9e4a0f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brand_networks(num_neurons, firing_rate, time, num_rates=None):\n",
    "    neurons = b2.NeuronGroup(num_neurons, 'dv/dt = -v/(10*ms) : 1', threshold='v>1', reset='v=0')\n",
    "\n",
    "    if num_rates is None:\n",
    "        # Use a single rate for all neurons\n",
    "        inputs = b2.PoissonInput(target=neurons, target_var='v', N=num_neurons, rate=firing_rate*b2.Hz, weight=1)\n",
    "    else:\n",
    "        # Use multiple rates for different neurons\n",
    "        input_rates = np.random.uniform(0, firing_rate, size=num_rates)\n",
    "        inputs = []\n",
    "        for i in range(num_neurons):\n",
    "            input_rate = input_rates[i % num_rates] * b2.Hz\n",
    "            input_ = b2.PoissonInput(target=neurons, target_var='v', N=1, rate=input_rate, weight=1)\n",
    "            inputs.append(input_)\n",
    "\n",
    "    spike_monitor = b2.SpikeMonitor(neurons)\n",
    "    net = b2.Network(neurons, inputs, spike_monitor)\n",
    "    net.run(time * b2.ms)  # Run the network instead of b2.run\n",
    "    return spike_monitor.spike_trains() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c2580a1-ad03-45f0-9382-41e3246e472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end - tagging and branding functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:brian_tutorial]",
   "language": "python",
   "name": "conda-env-brian_tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
